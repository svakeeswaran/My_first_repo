{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.88010276,  0.89390914,  0.51735246, -0.23711785,  0.32590532,\n",
       "        -2.21816274, -0.9881835 , -1.01513037,  0.06759557, -1.37321453]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mccormickml.com/2014/03/04/gradient-descent-derivation/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "def linearRegression(X,Y,n_epochs,learning_rate):\n",
    "    W = np.random.randn(X.shape[1],1)\n",
    "    B = 0\n",
    "    dW = np.zeros((X.shape[1],1))\n",
    "    dB = 0\n",
    "    for i in range(n_epochs):\n",
    "        estimated = np.dot(X,W) + B\n",
    "        SSE = np.sum(np.square(Y - estimated))\n",
    "        MSE = SSE/X.shape[0]\n",
    "        print(MSE)\n",
    "        dW = 1/X.shape[0] * np.dot(X.T,(estimated-Y))\n",
    "        dB = 1/X.shape[0] * np.sum((estimated-Y))\n",
    "        W = W - learning_rate * dW\n",
    "        B = B - learning_rate * dB\n",
    "        print(W.shape)\n",
    "    return W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "def logistic_regression(X,Y,n_epochs,learning_rate):\n",
    "    W = np.random.randn(X.shape[1],1)\n",
    "    B = 0\n",
    "    for i in range(n_epochs):\n",
    "        Z = np.dot(X,W) + B\n",
    "        Y_hat = 1/(1+np.exp(-Z))\n",
    "        print(Y_hat)\n",
    "        cross_entropy = -1 * np.sum(Y * np.log(Y_hat) + (1-Y) * np.log(1-Y_hat))\n",
    "        mean_cross_entropy = cross_entropy/X.shape[0]\n",
    "        print(mean_cross_entropy)\n",
    "        dW = 1/X.shape[0] * np.dot(X.T,(Y - Y_hat)) # Same as linear regression. Checked using partial derivatives.\n",
    "        dB = 1/X.shape[0] * np.sum(Y-Y_hat)\n",
    "        W = W - dW\n",
    "        B = B - dB\n",
    "    return W,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.randn(10,4)\n",
    "Y = np.random.randint(low=2,size=(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kMeansClustering(X,n_clusters,epochs):\n",
    "    #Getting initial centroids\n",
    "    centroids = X[np.random.choice(X.shape[0], n_clusters, replace=False)]\n",
    "    for i in range(epochs):\n",
    "        cluster = {}\n",
    "        for j in range(X.shape[0]):\n",
    "            dist = []\n",
    "            for k in range(centroids.shape[0]):\n",
    "                #Best way to calculate euclidean distance is using np.linalg.norm of the distance\n",
    "                dist.append(np.linalg.norm(centroids[k] - X[j]))\n",
    "            minDistance = dist.index(min(dist))\n",
    "            # Check if the index has been updated to the cluster hashmap. If not, update it\n",
    "            if minDistance not in cluster:\n",
    "                cluster[minDistance] = [j]\n",
    "            else:\n",
    "                cluster[minDistance].append(j)\n",
    "        for key,val in cluster.items():\n",
    "            points = X[val]\n",
    "            newPoint = np.sum(points,axis=0)\n",
    "            centroids[key] = newPoint\n",
    "        return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):\n",
    "    if len(x) != len(y):\n",
    "        return -1\n",
    "    else:\n",
    "        length = len(x)\n",
    "        ss = 0\n",
    "        for i in range(length):\n",
    "            ss+= (x[i] - y[i]) ** 2\n",
    "        return ss ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self,k):\n",
    "        self.k = k\n",
    "    \n",
    "    def vote(self,lis):\n",
    "        count = {}\n",
    "        for i in lis:\n",
    "            if i not in count:\n",
    "                count[i] = 1\n",
    "            else:\n",
    "                count[i]+=1\n",
    "                \n",
    "        maxVal = max(count.values())\n",
    "        proba = maxVal/len(lis)\n",
    "        for key,val in count.items():\n",
    "            if val == maxVal:\n",
    "                return key,proba\n",
    "            \n",
    "    def getMinIndex(self,distance):\n",
    "        distCopy = [i for i in distance]\n",
    "        distCopy.sort()\n",
    "        ans = []\n",
    "        ans = [distance.index(i) for i in distCopy[:self.k]]\n",
    "        return ans\n",
    "      \n",
    "            \n",
    "    def predict(self,train_X,train_Y,test_X):\n",
    "        distDict = {}\n",
    "        for i in range(len(test_X)):\n",
    "            distance = []\n",
    "            for j in range(len(train_X)):\n",
    "                dist = euclidean_distance(train_X[j],test_X[i])\n",
    "                distance.append(dist)\n",
    "            distDict[i] = distance\n",
    "        minDict = {}    \n",
    "        for key,val in distDict.items():\n",
    "            minDict[key] = self.getMinIndex(val)\n",
    "        ans = [0] * len(test_X)\n",
    "        proba = [0] * len(test_X)\n",
    "        for key,val in minDict.items():\n",
    "            relTest = [train_Y[i] for i in val]\n",
    "            ans[key],proba[key] = self.vote(relTest)\n",
    "        \n",
    "        return ans,proba\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = KNN(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [[1,2,3],[4,5,6],[7,8,9],[0,2,4],[5,4,6]]\n",
    "Y_train = [0,1,1,0,0]\n",
    "X_test = [[3,2,4],[5,4,5]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0], [1.0, 0.5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.predict(train_X=X_train,train_Y=Y_train,test_X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X_train)\n",
    "Y = np.array(Y_train)\n",
    "xT = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(xT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0. ],\n",
       "       [ 0.5,  0.5]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(xT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summedAreaTable(mat):\n",
    "    rows = len(mat)\n",
    "    cols = len(mat[0])\n",
    "    dp = [[0 for i in range(cols)] for j in range(rows)]\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if r==0 and c==0:\n",
    "                dp[r][c] = mat[r][c]\n",
    "            elif r == 0:\n",
    "                dp[r][c] = mat[r][c] + dp[r][c-1]\n",
    "            elif c == 0:\n",
    "                dp[r][c] = mat[r][c] + dp[r-1][c]\n",
    "            else:\n",
    "                dp[r][c] = mat[r][c] + dp[r-1][c] + dp[r][c-1] - dp[r-1][c-1]            \n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangleSum(beginRow,endRow,beginCol,endCol,grid):\n",
    "    summed = summedAreaTable(grid)\n",
    "    if beginRow -1 >= 0:\n",
    "        b = summed[beginRow-1][endCol]\n",
    "    else:\n",
    "        b = 0\n",
    "    if beginCol-1 >= 0:\n",
    "        c = summed[endRow][beginCol-1]\n",
    "    else:\n",
    "        c = 0\n",
    "    if (beginRow-1 >=0 and beginCol-1>=0):\n",
    "        d = summed[beginRow-1][beginCol-1]\n",
    "    else:\n",
    "        d = 0\n",
    "        \n",
    "    return summed[endRow][endCol] - b-c+d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rectangleSum(1,2,1,2,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rectangleSum(0,0,0,2,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
